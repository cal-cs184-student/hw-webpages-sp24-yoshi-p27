<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    background-color: white;
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
  kbd {
    color: #121212;
  }
</style>
<title>CS 184 Path Tracer</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">

<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    }
  };
</script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>

</head>


<body>

<h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2023</h1>
<h1 align="middle">Project 3-1: Path Tracer</h1>
<h2 align="middle">Aayush Patel</h2>

<!-- Add Website URL -->
<h2 align="middle">Website URL: <a href="https://cal-cs184-student.github.io/hw-webpages-sp24-yoshi-p27/">PAGE</a></h2>

<br><br>


<div align="center">
  <table style="width=100%">
      <tr>
          <td align="middle">
          <img src="./images/example_image.png" width="480px" />
          <figcaption align="middle">Results Caption: my bunny is the bounciest bunny</figcaption>
      </tr>
  </table>
</div>

<!--<p>All of the text in your write-up should be <em>in your own words</em>. If you need to add additional HTML features to this document, you can search the <a href="http://www.w3schools.com/">http://www.w3schools.com/</a> website for instructions. To edit the HTML, you can just copy and paste existing chunks and fill in the text and image file names appropriately.</p>-->
<!--<o>The website writeup is intended to be a self-contained walkthrough of the assignment: we want this to be a piece of work which showcases your understanding of relevant concepts through both mesh images as well as written explanations about what you did to complete each part of the assignment. Try to be as clear and organized as possible when writing about your own output files or extensions to the assignment. We want to understand what you've achieved and how you've done it!</p> -->
<!--<p>If you are well-versed in web development, feel free to ditch this template and make a better looking page.</p>-->


<!--<p>Here are a few problems students have encountered in the past. Test your website on the instructional machines early!</p>-->
<!--<ul>-->
<!--<li>Your main report page should be called index.html.</li>-->
<!--<li>Be sure to include and turn in all of the other files (such as images) that are linked in your report!</li>-->
<!--<li>Use only <em>relative</em> paths to files, such as <pre>"./images/image.jpg"</pre>-->
<!--Do <em>NOT</em> use absolute paths, such as <pre>"/Users/student/Desktop/image.jpg"</pre></li>-->
<!--<li>Pay close attention to your filename extensions. Remember that on UNIX systems (such as the instructional machines), capitalization matters. <pre>.png != .jpeg != .jpg != .JPG</pre></li>-->
<!--<li>Be sure to adjust the permissions on your files so that they are world readable. For more information on this please see this tutorial: <a href="http://www.grymoire.com/Unix/Permissions.html">http://www.grymoire.com/Unix/Permissions.html</a></li>-->
<!--<li>And again, test your website on the instructional machines early!</li>-->
<!--</ul>-->


<!--<p>Here is an example of how to include a simple formula:</p>-->
<!--<p align="middle"><pre align="middle">a^2 + b^2 = c^2</pre></p>-->
<!--<p>or, alternatively, you can include an SVG image of a LaTex formula.</p>-->

<!--<div>-->

<h2 align="middle">Overview</h2>
<p>
    In this project, I implemented a basic ray tracer to render large meshes, scenes, and objects in a variety of light conditions.
  This process began with the implementation of Ray Generation and Scene Intersection. Here a number of rays are created for each pixel in a scene, which are then sent out to intersect with
  primitives in the scene. The associated radiances are then averaged to give the originating pixel a color. After this, I implemented a bounding value heirarchy arlgorithm to make the calculations
  ray collisions with more efficient. After this, I implemented mutiple direct lighting functions to allow for more complex shading with external light sources.
  Then I implemented an indirect lighting function to allow for light which bounces off of objects and towards a point of interest. Finally, I implemented adaptive sampling for noise reduction.
</p>
<br>

<h2 align="middle">Part 1: Ray Generation and Scene Intersection (20 Points)</h2>
<!-- Walk through the ray generation and primitive intersection parts of the rendering pipeline.
Explain the triangle intersection algorithm you implemented in your own words.
Show images with normal shading for a few small .dae files. -->


<h3>
  Walk through the ray generation and primitive intersection parts of the rendering pipeline.
</h3>
<p>
  First I began this section by implementing a ray generation function. This begins with the transformation of the coordinates of an image to coordinates in camera space.
  We can then use these coordinates to generate a ray in camera space which goes from the camera to the coordinates. This can then be transformed into a ray in the world space, which will
  be useful for our calculations later on. After this, I implement the raytrace_pixel() function. In this function, I take random samples of over the area of a given pixel. I then use these to generate rays.
  These rays are then averaged to give us a Monte Carlo estimate of the radiance at the pixel.
</p>
<br>

<h3>
  Explain the triangle intersection algorithm you implemented in your own words.
</h3>
<p>
    We then traced these rays through the scene in order to determine if they intersected any objects in the scene. This required implementing two algorithms to check for these collisions.
  The first algorithm is for ray -sphere intersections. This was relatively simple since the bounds of a sphere are determined cleanly by a radius and a centroid.
  The second algorithm was for triangle intersection. The aim is to determine a point the ray intercepts in terms of the triangle's barycentric
  coordinates and check if that point is within the triangle. The algorithm begins by defining a vector [t, b1, b2] which we will set up
  a system of equations to determine the value of. t is the "time" where the ray may intersect a triangle, and b1 and b2 are the barycentric coordinates
  of the associated point of intersection. This is set equal to 1/dot(s1, e1) * [dot(s2, e2), dot(s1, s), dot(s2, d)]. These
  new values are determined by the Moller Trumbore algorithm. e1 = p1 - p0, where p1 and p0 are the coordinates corresponding to two corners of the triangle.
  e2 = p2 - p0 where p2 is the last point of the triangle. s = o - p0 where o is the origin of our ray. s1 = d * e2 where d  is the direction of our ray.
  s2 = s *e1. Now if b1, b2, and 1-b1-b2 are between 0 and 1, then we know there is an intersection between the ray and the triangle at time t. If the previous conditions aren't met, or the
  time t is outside of the minimum t and maximum t values associated with the ray, there is not an intersection between the ray and the triangle.
</p>
<br>

<h3>
  Show images with normal shading for a few small .dae files.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="./images/CBemptysimple.png" align="middle" width="400px"/>
        <figcaption>CBempty.dae</figcaption>
      </td>
      <td>
        <img src="./images/CBspheresSimple.png" align="middle" width="400px"/>
        <figcaption>CBsphere.dae</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="./images/cow.png" align="middle" width="400px"/>
        <figcaption>cow.dae</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>


<h2 align="middle">Part 2: Bounding Volume Hierarchy (20 Points)</h2>
<!-- Walk through your BVH construction algorithm. Explain the heuristic you chose for picking the splitting point.
Show images with normal shading for a few large .dae files that you can only render with BVH acceleration.
Compare rendering times on a few scenes with moderately complex geometries with and without BVH acceleration. Present your results in a one-paragraph analysis. -->

<h3>
  Walk through your BVH construction algorithm. Explain the heuristic you chose for picking the splitting point.
</h3>
<p>
    The intuition behind the BVH acceleration algorithm is that we are trying to quickly exclude primitives which a
  ray is guaranteed to not hit. In order to do this, I construct a binary tree which can be traversed to find the region of primitives
  a particular ray will intersect. The algorithm proceeds as follows.
</p>
  <p>We begin by iterating through the vector of all primitives between the start and end positions in the given to us.
  In the loop we generate a bounding box for the primitive in question. Then we check if the coordinates of the bounding box contain our given primitive.
  if it does, we move on to the next primitive. If it doesn't, the newly generated bounding box is expanded to include the primitive in question in the loop.
  I then choose a heuristic upon which to partition the bounding box into two nodes, right and left. I chose to use the median of a fixed axis, z. I think it would have been ideal to do this split along the largest of the three axis in a particular bounding box
  to get a less flat, more efficiently allocated bounding box. I may have avoided some tough bugs where small edge cases seg faulted when I used other singular axes. However, the z axis generally functions well. Before splitting the primitives vertex, I initialize a BVHnode. If the
    number of primitives between start and end are less than the max_leaf_size, which is passed in, then we can treat this node as a leaf and just assign the start and end values to the ones passed in and return. This is our base case.
  If the base case condition is not met, I split the list of primitives about the axis, assigning them to two vectors, one for the right and one for the left.
  I then recursively call construct_bvh() on the left and right vectors, assigning the results to the left and right leaves of the BVHonde.</p>

<h3>
  Show images with normal shading for a few large .dae files that you can only render with BVH acceleration.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="./images/beast.png" align="middle" width="400px"/>
        <figcaption>beast.dae</figcaption>
      </td>
      <td>
        <img src="./images/maxplancklarge.png" align="middle" width="400px"/>
        <figcaption>maxplanck.dae</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="./images/teapot.png" align="middle" width="400px"/>
        <figcaption>teapot.dae</figcaption>
      </td>
      <td>
        <img src="./images/beetle.png" align="middle" width="400px"/>
        <figcaption>beetle.dae</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>

<h3>
  Compare rendering times on a few scenes with moderately complex geometries with and without BVH acceleration. Present your results in a one-paragraph analysis.
</h3>
<p>
    Rendering times were signfiicantly faster with BVH acceleration. This was particularly noticable in the maxPlanck.dae
  file which I could nearly not render at all, but rendered in a few minutes after acceleration. It was also signficantly faster for the cow.dae
  file than before.
</p>
<br>

<h2 align="middle">Part 3: Direct Illumination (20 Points)</h2>
<!-- Walk through both implementations of the direct lighting function.
Show some images rendered with both implementations of the direct lighting function.
Focus on one particular scene with at least one area light and compare the noise levels in soft shadows when rendering with 1, 4, 16, and 64 light rays (the -l flag) and with 1 sample per pixel (the -s flag) using light sampling, not uniform hemisphere sampling.
Compare the results between uniform hemisphere sampling and lighting sampling in a one-paragraph analysis. -->

<h3>
  Walk through both implementations of the direct lighting function.
</h3>
<p>
    The first implementation of the direct lighting function was hemisphere sampling. In this sampleing algorithm, we take our hit with the primitive which was passed in and generate num_sample rays
  from the hit point in the direction of the sample directions. These directions are sampled by taking random points from a hemisphere in the space, treating all these sampled rays as equally important.
  Then for each of these rays we check if there is an intersection with something else in the world space. If there is an itnersection we get the rays radiance by calling get radiance
  from the intersections bsdf field. We then evaluate the bsdf taking the sampled from the hemisphere as the incident ray and the outgoing ray which heads towards the camera.
  This is then multiplied by the radiance calculated earlier and the cosine of the angle of the hemisphere sampled ray and the normal at the poit of the intersection. This value is then divided by the pdf for equally weighted rays sampled from
  the hemisphere which is 1/(2*PI).

</p>

  <p>
    The second implementation of the direct lighting function was importance sampling. Here the aim is not to sample fom the entire hemisphere
    but from lights only. We iterate through all the lights in the scene. If the light is a pointt light we only sample it once. Otherwise the following logic will be identical
    for non-point light cases. For each light we first take n samples of the light which gives us the radiance of the light
    then we calculate and create a new ray using the incident direction of this newly sampled light and the hit oint.
    Then, if the ray does not have an external intersection, we perform the same reflection equation calculations as in hemisphere sampling and
    aggregate accordingly.
  </p>

<h3>
  Show some images rendered with both implementations of the direct lighting function.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <!-- Header -->
    <tr align="center">
      <th>
        <b>Uniform Hemisphere Sampling</b>
      </th>
      <th>
        <b>Light Sampling</b>
      </th>
    </tr>
    <br>
    <tr align="center">
      <td>
        <img src="./images/CBbunny_H_16_8.png" align="middle" width="400px"/>
        <figcaption>CBBunny.dae with hemisphere sampling</figcaption>
      </td>
      <td>
        <img src="./images/CBbunny_16_8.png" align="middle" width="400px"/>
        <figcaption>example1.dae</figcaption>
      </td>
    </tr>
    <br>
    <tr align="center">
      <td>
        <img src="images/CBsphereH.png" align="middle" width="400px"/>
        <figcaption>example2.dae</figcaption>
      </td>
      <td>
        <img src="images/CBspherenoH.png" align="middle" width="400px"/>
        <figcaption>example2.dae</figcaption>
      </td>
    </tr>
    <br>
  </table>
</div>
<br>

<h3>
  Focus on one particular scene with at least one area light and compare the noise levels in <b>soft shadows</b> when rendering with 1, 4, 16, and 64 light rays (the -l flag) and with 1 sample per pixel (the -s flag) using light sampling, <b>not</b> uniform hemisphere sampling.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="./images/CBspheres1.png" align="middle" width="200px"/>
        <figcaption>1 Light Ray (CBspheres.dae)</figcaption>
      </td>
      <td>
        <img src="./images/CBspheres4.png" align="middle" width="200px"/>
        <figcaption>4 Light Rays (CBspheres.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="./images/CBspheres16.png" align="middle" width="200px"/>
        <figcaption>16 Light Rays (CBspheres.dae)</figcaption>
      </td>
      <td>
        <img src="./images/CBspheres64.png" align="middle" width="200px"/>
        <figcaption>64 Light Rays (CBspheres.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<p>
</p>
<br>

<h3>
  Compare the results between uniform hemisphere sampling and lighting sampling in a one-paragraph analysis.
</h3>
<p>
    Uniform hemisphere sampling tends to result in significantly more noise than lighting sampling, particularly in the soft shadow areas of the scene. It also tends to result in less consistent, much
  much softer shadows in general. In general, light sampling tends to have the effect of significantly reducing noise and increasing sharpness of the image as a result Beyond this, render times seem fairly similar, meaning that it seems rarely advatageous to use hemisphere sampling instead
  of lighting sampling -- at least for the sizes of the renders that we used.
</p>
<br>


<h2 align="middle">Part 4: Global Illumination (20 Points)</h2>
<!-- Walk through your implementation of the indirect lighting function.
Show some images rendered with global (direct and indirect) illumination. Use 1024 samples per pixel.
Pick one scene and compare rendered views first with only direct illumination, then only indirect illumination. Use 1024 samples per pixel. (You will have to edit PathTracer::at_least_one_bounce_radiance(...) in your code to generate these views.)
For CBbunny.dae, compare rendered views with max_ray_depth set to 0, 1, 2, 3, and 100 (the -m flag). Use 1024 samples per pixel.
Pick one scene and compare rendered views with various sample-per-pixel rates, including at least 1, 2, 4, 8, 16, 64, and 1024. Use 4 light rays.
You will probably want to use the instructional machines for the above renders in order to not burn up your own computer for hours. -->

<h3>
  Walk through your implementation of the indirect lighting function.
</h3>
<p>
    Implementing indirect lighting allows primitives in the scene which do not have a light hitting them directly to still
  be illuminated by reflections off the surrounding areas. You may have noticed that the ceilings in images with a zone light in them
  are completely dark. However, you rarely see a conpletely dark ceiling with a light in it. This is because it is illuminated by the reflected light.

</p>
<p>
  First I use a coin flip function with a probability of .3 to check if the image ray should randomly be terminated
  as part of the russian roulette implementation. I also check that this only occurs if the ray has bounced more than once.
  If the rays depth is 0, the function also terminates. If not, evaluate the bsdf of the intersection using the same method as in previous functions, except that we call the sample_f
  wrapper which also returns a pointer to the incident ray and the pdf. Then I generate a new ray, assigning its depth to the size of the input ray minus 1 to decrement the ray.
  If we are accumulating bounces, we check if there is an intersection for this new ray. If so, we check if there have been more than one bounces, we recursivley call the function on the new ray and the new intersection. WE then multiply
  this by the evaluated bsdf, the cosign value of the angle between the incident and the normal of the intersection, divided by the pdf and (1-0.3). This value is added to the one_bounce_radiance value.
  If there has not been more than one bounce, I don't divide it by (1-.3) since russian roulette shouldn't be applied to rays that haven't bounced more than once.

  If we are not accumulating bounces, the logic is similar, except if the intersection occurs, but the light has more bounces left before it is supposed to terminate, then the computed values are added to a zero vector
  instead of the one bounce value.
</p>
<br>

<h3>
  Show some images rendered with global (direct and indirect) illumination. Use 1024 samples per pixel.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="./images/lamb_demo.png" align="middle" width="400px"/>
        <figcaption>CBSphere_lambertian.dae</figcaption>
      </td>
      <td>
        <img src="./images/bunny4-5-2.png" align="middle" width="400px"/>
        <figcaption>example2.dae</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>

<h3>
  Pick one scene and compare rendered views first with only direct illumination, then only indirect illumination. Use 1024 samples per pixel. (You will have to edit PathTracer::at_least_one_bounce_radiance(...) in your code to generate these views.)
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="./images/sphereDirect.png" align="middle" width="400px"/>
        <figcaption>Only direct illumination (example1.dae)</figcaption>
      </td>
      <td>
        <img src="./images/sphereIndirect.png" align="middle" width="400px"/>
        <figcaption>Only indirect illumination (example1.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>
<p>
    YOUR EXPLANATION GOES HERE
</p>
<br>



<h3>
  For CBbunny.dae, compare rendered views with max_ray_depth set to 0, 1, 2, 3, 4, and 5 (the -m flag). Use 1024 samples per pixel Bounces
   are not accumulated here.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
      <td>
        <img src="./images/bunny-4-5.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 5 (CBbunny.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>
<p>
   I was not able to render all of the bunny images here due to hardware limitations. It was taking unreasonably long, even with allocation of a few hours. I was also never able to ssh into instructional machines. I even tried running code on friends computers with 
   slightly more powerful gpus (m1 macbook air vs m1 macbook pro), with little improvement. In testing, though I was able render the spheres file. As I moved from the second to third bounces of light
  the image darkens significantly, with very little bounced illumination present on the objects. The second bounce still allows for some notable reflection
  from around the scene, as seen by the illumination on the figures near the bottom. As such the objects are sharper as are the shadows.

</p>
<br>

  <h3>
    For CBbunny.dae, compare rendered views with max_ray_depth set to 0, 1, 2, 3, 4, and 5 (the -m flag). Use 1024 samples per pixel.
  </h3>
  <!-- Example of including multiple figures -->
  <div align="middle">
    <table style="width:100%">
      <tr align="center">
        <td>
          <img src="./images/bunny4-6-0.png" align="middle" width="400px"/>
          <figcaption>max_ray_depth = 0 (CBbunny.dae)</figcaption>
        </td>
        <td>
          <img src="./images/bunny4-5-1.png" align="middle" width="400px"/>
          <figcaption>max_ray_depth = 1 (CBbunny.dae)</figcaption>
        </td>
      </tr>
      <tr align="center">
        <td>
          <img src="./images/bunny4-5-2.png" align="middle" width="400px"/>
          <figcaption>max_ray_depth = 2 (CBbunny.dae)</figcaption>
        </td>
        <td>
          <img src="./images/bunny4-5-3.png" align="middle" width="400px"/>
          <figcaption>max_ray_depth = 3 (CBbunny.dae)</figcaption>
        </td>
      </tr>
      <tr align="center">
        <td>
          <img src="./images/bunny4-5-4.png" align="middle" width="400px"/>
          <figcaption>max_ray_depth = 4 (CBbunny.dae)</figcaption>
        </td>
        <td>
          <img src="./images/bunny4-5-5.png" align="middle" width="400px"/>
          <figcaption>max_ray_depth = 5 (CBbunny.dae)</figcaption>
        </td>
      </tr>
    </table>
  </div>
  <br>
  <p>
    Here we can see the that as max bounce increases, the shadows gradually become less harsh. Additionally areas of the image which aren't directly exposed
    to light generally become a little bit brighter. After the third or fourth bounce though, differences become less and less apparent from
    image to image, as light rays dissipate
  </p>
  <br>



<h3>
  For CBbunny.dae, compare rendered views with max_ray_depth set to 0, 1, 2, 3, and 100 (the -m flag). Use 1024 samples per pixel (Russian-Roulette).
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="./images/bunny4-6-0.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 0 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="./images/bunny4-6-1.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 1 (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="./images/bunny4-6-2.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 2 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="./images/bunny4-6-3.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 3 (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="./images/bunny4-6-4.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 4 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="./images/bunny4-6-100.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 100 (CBbunny.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>
<p>
    Here with russian roulette included, the images seem to be slightly darker than in the previous section, after the first bounce
  since rays are gradually eliminated. There is also a minimal difference between the 100 ray render and the 5 ray render from the previous section
  since there are already diminishing returns at higher ray bounces as the light becomes less powerful, and russian roulette eliminates
  a good amount of rays by that point. As such, the render was not much slower than with max depth of 4.
</p>
<br>

<h3>
  Pick one scene and compare rendered views with various sample-per-pixel rates, including at least 1, 2, 4, 8, 16, 64, and 1024. Use 4 light rays.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="./images/spheres4-7-1.png" align="middle" width="400px"/>
        <figcaption>1 sample per pixel (CBsphere_lambertian.dae)</figcaption>
      </td>
      <td>
        <img src="./images/spheres4-7-2.png" align="middle" width="400px"/>
        <figcaption>2 samples per pixel (CBsphere_lambertian.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="./images/spheres4-7-4.png" align="middle" width="400px"/>
        <figcaption>4 samples per pixel (CBsphere_lambertian.dae)</figcaption>
      </td>
      <td>
        <img src="./images/spheres4-7-8.png" align="middle" width="400px"/>
        <figcaption>8 samples per pixel (CBsphere_lambertian.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="./images/spheres4-7-16.png" align="middle" width="400px"/>
        <figcaption>16 samples per pixel (CBsphere_lambertian.dae)</figcaption>
      </td>
      <td>
        <img src="./images/spheres4-7-64.png" align="middle" width="400px"/>
        <figcaption>64 samples per pixel (CBsphere_lambertian.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="./images/spheres4-7-1024.png" align="middle" width="400px"/>
        <figcaption>1024 samples per pixel (CBsphere_lambertian.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>
<p>
    As samples increase the noise in each image decreases substantially. As such, shadows become sharper, objects become more clear
  and the image tends to appear a little bit brighter due to better coverage from more samples.
</p>
<br>


<h2 align="middle">Part 5: Adaptive Sampling (20 Points)</h2>
<!-- Explain adaptive sampling. Walk through your implementation of the adaptive sampling.
Pick one scene and render it with at least 2048 samples per pixel. Show a good sampling rate image with clearly visible differences in sampling rate over various regions and pixels. Include both your sample rate image, which shows your how your adaptive sampling changes depending on which part of the image you are rendering, and your noise-free rendered result. Use 1 sample per light and at least 5 for max ray depth. -->

<h3>
  Explain adaptive sampling. Walk through your implementation of the adaptive sampling.
</h3>
<p>
    Adaptive sampling allows for more efficient allocation of per pixel samples. This happens by stopping sampling early when sampled light rays begin to converge, allowing more resources
  to be allocated towards higher sample rates for less flat, more detailed sections of the image where convergence happens later. I implemented this
  by first tracking the illuminance values of each radiance value of each ray we sample. We add the value to s1 and the squared value to s2.
  Now in each loop in the algorithm we check if there have been samplesPerBatch samples since the last convergence check. If there have been,
  we take the mean of the illuminances using the s1 value and the number of samples taken so far
  and then we take the variance of the illuminances using the s2 values. We then calculate
  a constan in order to get 95 percent confidence intervals for convergence, by multiplying 1.96* the std_dev divided by the square root of the samples taken.
  If this constant is less than the maxTolerances * mean, we break early and take no more samples for the pixel since we are reasonably sure the pixels have converged.
</p>
<br>

<h3>
  Pick two scenes and render them with at least 2048 samples per pixel. Show a good sampling rate image with clearly visible differences in sampling rate over various regions and pixels. Include both your sample rate image, which shows your how your adaptive sampling changes depending on which part of the image you are rendering, and your noise-free rendered result. Use 1 sample per light and at least 5 for max ray depth.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="./images/bunny.png" align="middle" width="400px"/>
        <figcaption>Rendered image (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/bunny_rate.png" align="middle" width="400px"/>
        <figcaption>Sample rate image (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/spheresBig.png" align="middle" width="400px"/>
        <figcaption>Rendered image (CBspheres_lambertian.dae)</figcaption>
      </td>
      <td>
        <img src="./images/spheresBig_rate.png" align="middle" width="400px"/>
        <figcaption>Sample rate image (CBspheres_lambertian)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>


</body>
</html>
